{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc6ac82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bafdd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = './texts/gretil/sa_kAlidAsa-raghuvaMza.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b64f4536",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d805753f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xml.etree.ElementTree.ElementTree at 0x7fe40e9963e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa12ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tree.getroot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da170894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element '{http://www.tei-c.org/ns/1.0}TEI' at 0x7fe40e28f1f0>\n"
     ]
    }
   ],
   "source": [
    "print(root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24fff30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'{http://www.w3.org/XML/1998/namespace}lang': 'en'}\n"
     ]
    }
   ],
   "source": [
    "print(root[0].attrib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "102118f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e0aacfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasyap/anaconda3/lib/python3.9/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open(loc, 'r') as tei:\n",
    "    soup = BeautifulSoup(tei, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b81515fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Raghuvaṃśa</title>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88b7b951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Raghuvaṃśa'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.getText()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2363a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.abstract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bf88032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tei(tei_file):\n",
    "    with open(tei_file, 'r') as tei:\n",
    "        soup = BeautifulSoup(tei, 'lxml')\n",
    "        return soup\n",
    "    raise RuntimeError('Cannot generate a soup from the input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e57e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = read_tei(loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54db4e4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28321/1644596436.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparse_tei\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_28321/3279222978.py\u001b[0m in \u001b[0;36mparse_tei\u001b[0;34m(link)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_tei\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdivs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"div\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "parse_tei(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dd3949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tei(link):\n",
    "    result = BeautifulSoup(link.text,'xml')\n",
    "    body = result.find('body') \n",
    "    divs = body.find_all(\"div\", recursive=False)\n",
    "    title=result.find('title').text\n",
    "    base_text={}\n",
    "    if divs and divs[0].find_all('div',recursive=False) == None:\n",
    "        if len(divs) == 1:\n",
    "            divs = divs[0].find_all('div',recursive=False)               \n",
    "        for div in divs:\n",
    "            filename = title if div.find(\"head\") == None else div.find(\"head\").text\n",
    "            text = change_text_format(div.get_text().replace(filename,'').strip(\"\\n\"))\n",
    "            base_text.update({filename:text})         \n",
    "    meta,src_meta =get_metadata(result)\n",
    "    opf_path = create_opf(base_text,meta)\n",
    "    opf_path = Path(opf_path)\n",
    "    create_readme(opf_path,src_meta)\n",
    "    publish_pecha(opf_path.parent)\n",
    "    pechas_catalog.info(f\"{opf_path.stem},{src_meta['title']}\")\n",
    "    print(src_meta['title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf366667",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openpecha'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28321/1771926869.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopenpecha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpecha\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenPechaFS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopenpecha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInitialCreationEnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayerEnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPechaMetaData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openpecha'"
     ]
    }
   ],
   "source": [
    "from cgitb import lookup\n",
    "from distutils.log import INFO\n",
    "import logging\n",
    "from bs4 import BeautifulSoup\n",
    "from openpecha.core.pecha import OpenPechaFS\n",
    "from openpecha.core.layer import InitialCreationEnum, Layer, LayerEnum,PechaMetaData\n",
    "from datetime import datetime\n",
    "from openpecha import github_utils,config\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import re\n",
    "import logging\n",
    "\n",
    "pechas_catalog = ''\n",
    "err_log = ''\n",
    "\n",
    "\n",
    "start_url = 'http://gretil.sub.uni-goettingen.de/gretil.html'\n",
    "pre_url = 'http://gretil.sub.uni-goettingen.de/'\n",
    "\n",
    "\n",
    "def make_request(url):\n",
    "    response = requests.get(url)\n",
    "    return response\n",
    "\n",
    "\n",
    "def parse_page(url):\n",
    "    page = make_request(url)\n",
    "    soup = BeautifulSoup(page.text,'html.parser')\n",
    "    outlines = soup.find_all('div',attrs={'class':'outline-5'})\n",
    "    parse_links(outlines)\n",
    "\n",
    "\n",
    "def parse_links(outlines):\n",
    "    for outline in outlines:\n",
    "        ol = outline.find('ol',attrs={'class':'org-ol'})\n",
    "        lis = ol.find_all('li',recursive=False)\n",
    "        for li in lis:\n",
    "            link = li.find('a',text = 'TEI-conformant XML')\n",
    "            if link:\n",
    "                try:\n",
    "                    parse_tei(link['href'])\n",
    "                except:\n",
    "                    err_log.info(f\"err {link['href']}\")    \n",
    "                \n",
    "\n",
    "def parse_tei(link):\n",
    "    xml = make_request(pre_url+link)\n",
    "    if xml:\n",
    "        result = BeautifulSoup(xml.text,'xml')\n",
    "        body = result.find('body') \n",
    "        divs = body.find_all(\"div\", recursive=False)\n",
    "        title=result.find('title').text\n",
    "        base_text={}\n",
    "        if divs and divs[0].find_all('div',recursive=False) == None:\n",
    "            if len(divs) == 1:\n",
    "                divs = divs[0].find_all('div',recursive=False)               \n",
    "            for div in divs:\n",
    "                filename = title if div.find(\"head\") == None else div.find(\"head\").text\n",
    "                text = change_text_format(div.get_text().replace(filename,'').strip(\"\\n\"))\n",
    "                base_text.update({filename:text})         \n",
    "        else:\n",
    "            text = change_text_format(body.get_text().strip(\"\\n\"))\n",
    "            base_text.update({title:text})\n",
    "        meta,src_meta =get_metadata(result)\n",
    "        opf_path = create_opf(base_text,meta)\n",
    "        opf_path = Path(opf_path)\n",
    "        create_readme(opf_path,src_meta)\n",
    "        publish_pecha(opf_path.parent)\n",
    "        pechas_catalog.info(f\"{opf_path.stem},{src_meta['title']}\")\n",
    "        print(src_meta['title'])\n",
    "\n",
    "\n",
    "def change_text_format(text):\n",
    "    re_pattern = \"\\n\\n+\"\n",
    "    new_text = re.sub(re_pattern,\"\\n\\n\",text)\n",
    "    return new_text\n",
    "\n",
    "\n",
    "def create_opf(base_text,meta):\n",
    "    opf_path=f\"opfs/\"\n",
    "    \n",
    "    opf = OpenPechaFS(\n",
    "        meta=meta,\n",
    "        base=base_text\n",
    "        )\n",
    "    opf_path = opf.save(output_path=opf_path)\n",
    "\n",
    "    return opf_path\n",
    "\n",
    "\n",
    "def get_metadata(result):\n",
    "    src_meta = parse_src_meta(result)\n",
    "    instance_meta = PechaMetaData(\n",
    "        initial_creation_type=InitialCreationEnum.input,\n",
    "        created_at=datetime.now(),\n",
    "        last_modified_at=datetime.now(),\n",
    "        source_metadata=src_meta)\n",
    "    return instance_meta,src_meta    \n",
    "\n",
    "\n",
    "def parse_src_meta(result):\n",
    "    src_meta = {}\n",
    "    title_stmt = result.find('titleStmt')\n",
    "    profileDesc = result.find('profileDesc')\n",
    "    respStmt = title_stmt.find_all('respStmt')\n",
    "    languages = profileDesc.find_all('language')\n",
    "    src_meta.update({'title':title_stmt.find(\"title\").text})\n",
    "    src_meta.update({'language':[x.text for x in languages]})\n",
    "    src_meta.update({'term':profileDesc.find('term').text})\n",
    "    for elem in respStmt:\n",
    "        src_meta.update({elem.find('resp').text:elem.find('name').text})\n",
    "    return src_meta\n",
    "\n",
    "\n",
    "def create_readme(opf_path,src_meta):\n",
    "    readme_path = opf_path.parent / 'readme.md'\n",
    "    pecha_id = opf_path.stem\n",
    "    pecha = f\"|Pecha id | {pecha_id}\"\n",
    "    Table = \"| --- | --- \"\n",
    "    Title = f\"|Title | {src_meta['title']} \"\n",
    "    lang = f\"|Language | {src_meta['language']}\"\n",
    "    source = f\"|Source | 'GRETIL'\"\n",
    "    readme = f\"{pecha}\\n{Table}\\n{Title}\\n{lang}\\n{source}\"\n",
    "    Path(readme_path).touch()\n",
    "    Path(readme_path).write_text(readme)\n",
    "\n",
    "\n",
    "def publish_pecha(opf_path):\n",
    "    github_utils.github_publish(\n",
    "    opf_path,\n",
    "    not_includes=[],\n",
    "    message=\"initial commit\"\n",
    "    )\n",
    "\n",
    "\n",
    "def set_up_logger(logger_name):\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    formatter = logging.Formatter(\"%(message)s\")\n",
    "    fileHandler = logging.FileHandler(f\"{logger_name}.log\")\n",
    "    fileHandler.setFormatter(formatter)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.addHandler(fileHandler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "def main():\n",
    "    global pechas_catalog,err_log\n",
    "    pechas_catalog = set_up_logger(\"pechas_catalog\")\n",
    "    err_log = set_up_logger('err')\n",
    "    parse_page(start_url)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e46746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
